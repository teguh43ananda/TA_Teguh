{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d2508b",
   "metadata": {},
   "source": [
    "CELL 1 — Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb32e4",
   "metadata": {},
   "source": [
    "CELL 2 — Konfigurasi path trial yang mau dibandingkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d60f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECTS = list(\"ABCDEFGHIJ\")\n",
    "TRIALS = list(range(1, 73))\n",
    "\n",
    "\n",
    "TRIAL_ROOTS = {\n",
    "    \"Trial_1\":  Path(r\"E:\\0.TA_Teguh\\GMM Trial 1\"),  \n",
    "    \"Trial_2\":  Path(r\"E:\\0.TA_Teguh\\GMM Trial 2\"), \n",
    "    \"Trial_3\":  Path(r\"E:\\0.TA_Teguh\\GMM Trial 3\"),   \n",
    "    \"Trial_4\":  Path(r\"E:\\0.TA_Teguh\\GMM Trial 4\"),  \n",
    "    \"Trial8\": Path(r\"E:\\0.TA_Teguh\\GMM Trial 8\"),  \n",
    "}\n",
    "\n",
    "# Nama file yang diharapkan\n",
    "def head2_path(root: Path, subject: str, trial: int) -> Path:\n",
    "    return root / \"Head 2\" / subject / f\"Jalan{trial}.csv\"\n",
    "\n",
    "def head3_path(root: Path, subject: str, trial: int) -> Path:\n",
    "    return root / \"Head 3\" / subject / f\"Jalan{trial}.jsonl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e9dad6",
   "metadata": {},
   "source": [
    "CELL 3 — Loader Head-2 (frame-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_head2_one_file(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Wajib minimal punya kolom:\n",
    "    - frame\n",
    "    - N_roi\n",
    "    - valid_minpts  (0/1)\n",
    "    - N_inlier\n",
    "    - conf          (0..1)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    # Normalize kolom yang umum (jaga-jaga variasi nama)\n",
    "    col_map = {}\n",
    "    for c in df.columns:\n",
    "        cl = c.strip().lower()\n",
    "        if cl == \"frame\":\n",
    "            col_map[c] = \"frame\"\n",
    "        elif cl in [\"n_roi\", \"nroi\", \"points_roi\", \"roi_points\"]:\n",
    "            col_map[c] = \"N_roi\"\n",
    "        elif cl in [\"valid_minpts\", \"valid\", \"valid_frame\"]:\n",
    "            col_map[c] = \"valid_minpts\"\n",
    "        elif cl in [\"n_inlier\", \"ninlier\", \"points_inlier\", \"inlier_points\"]:\n",
    "            col_map[c] = \"N_inlier\"\n",
    "        elif cl in [\"conf\", \"confidence\"]:\n",
    "            col_map[c] = \"conf\"\n",
    "\n",
    "    df = df.rename(columns=col_map)\n",
    "\n",
    "    required = [\"frame\", \"N_roi\", \"valid_minpts\", \"N_inlier\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns {missing} in {path}\")\n",
    "\n",
    "    df[\"frame\"] = df[\"frame\"].astype(int)\n",
    "    for c in [\"N_roi\", \"N_inlier\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "    df[\"valid_minpts\"] = pd.to_numeric(df[\"valid_minpts\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    if \"conf\" in df.columns:\n",
    "        df[\"conf\"] = pd.to_numeric(df[\"conf\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"conf\"] = np.nan\n",
    "\n",
    "    # inlier_ratio (aman walau N_roi=0)\n",
    "    df[\"inlier_ratio\"] = np.where(df[\"N_roi\"] > 0, df[\"N_inlier\"] / df[\"N_roi\"], np.nan)\n",
    "\n",
    "    return df.sort_values(\"frame\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1383c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_trial_roots(max_show=5):\n",
    "    print(\"Sanity check TRIAL_ROOTS ...\")\n",
    "    for name, root in TRIAL_ROOTS.items():\n",
    "        h2 = root / \"Head 2\"\n",
    "        h3 = root / \"Head 3\"\n",
    "        ok = root.exists() and h2.exists() and h3.exists()\n",
    "        print(f\"- {name:12s} | exists={root.exists()} | Head2={h2.exists()} | Head3={h3.exists()} | OK={ok}\")\n",
    "\n",
    "        # cek contoh 1 file: A/Jalan1\n",
    "        sample_h2 = head2_path(root, \"A\", 1)\n",
    "        sample_h3 = head3_path(root, \"A\", 1)\n",
    "        print(f\"    sample H2: {sample_h2.exists()}  ({sample_h2})\")\n",
    "        print(f\"    sample H3: {sample_h3.exists()}  ({sample_h3})\")\n",
    "\n",
    "sanity_check_trial_roots()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86804f3",
   "metadata": {},
   "source": [
    "CELL 4 — Loader Head-3 (μ per frame) + centroid jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5147bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_head3_one_file(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    JSONL, tiap baris minimal punya:\n",
    "    - frame\n",
    "    - mu : [x,y,z]\n",
    "    Optional: Sigma, threshold, dsb\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            frame = int(obj.get(\"frame\"))\n",
    "            mu = obj.get(\"mu\", None)\n",
    "            if mu is None or len(mu) != 3:\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"frame\": frame,\n",
    "                \"mu_x\": float(mu[0]),\n",
    "                \"mu_y\": float(mu[1]),\n",
    "                \"mu_z\": float(mu[2]),\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    df = df.sort_values(\"frame\").reset_index(drop=True)\n",
    "\n",
    "    # centroid jitter: delta mu per frame valid (berurutan di df)\n",
    "    dx = df[\"mu_x\"].diff()\n",
    "    dy = df[\"mu_y\"].diff()\n",
    "    dz = df[\"mu_z\"].diff()\n",
    "    df[\"dmu\"] = np.sqrt(dx*dx + dy*dy + dz*dz)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04ad02",
   "metadata": {},
   "source": [
    "CELL 5 — Hitung metrik per file (Trial x Subject x Jalan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd2d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mid_gaps(valid_series: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Hitung jumlah frame invalid yang berada DI TENGAH segmen valid.\n",
    "    Definisi sederhana:\n",
    "    - cari frame valid pertama dan terakhir\n",
    "    - hitung invalid di antara keduanya\n",
    "    \"\"\"\n",
    "    idx_valid = np.where(valid_series.values == 1)[0]\n",
    "    if len(idx_valid) == 0:\n",
    "        return int(len(valid_series))  # semua invalid dianggap gap besar\n",
    "    first_v = idx_valid[0]\n",
    "    last_v  = idx_valid[-1]\n",
    "    mid = valid_series.values[first_v:last_v+1]\n",
    "    return int(np.sum(mid == 0))\n",
    "\n",
    "def evaluate_one_file(trial_name: str, root: Path, subject: str, trial: int) -> dict:\n",
    "    p2 = head2_path(root, subject, trial)\n",
    "    p3 = head3_path(root, subject, trial)\n",
    "\n",
    "    if not p2.exists():\n",
    "        return {\n",
    "            \"trial_name\": trial_name,\n",
    "            \"subject\": subject,\n",
    "            \"trial\": trial,\n",
    "            \"status\": \"missing_head2\",\n",
    "        }\n",
    "\n",
    "    h2 = load_head2_one_file(p2)\n",
    "\n",
    "    frames_total = int(h2[\"frame\"].nunique())\n",
    "    frames_valid = int((h2[\"valid_minpts\"] == 1).sum())\n",
    "    valid_rate = frames_valid / frames_total if frames_total > 0 else 0.0\n",
    "\n",
    "    mid_gaps = count_mid_gaps(h2[\"valid_minpts\"]) if frames_total > 0 else 0\n",
    "    mid_gap_ratio = mid_gaps / frames_total if frames_total > 0 else 0.0\n",
    "\n",
    "    # frames_empty_after: valid_minpts=1 tapi N_inlier=0\n",
    "    frames_empty_after = int(((h2[\"valid_minpts\"] == 1) & (h2[\"N_inlier\"] == 0)).sum())\n",
    "\n",
    "    # inlier_ratio stats (hanya frame valid dan N_roi>0)\n",
    "    mask_ratio = (h2[\"valid_minpts\"] == 1) & (h2[\"N_roi\"] > 0)\n",
    "    inlier_ratio_med = float(h2.loc[mask_ratio, \"inlier_ratio\"].median()) if mask_ratio.any() else np.nan\n",
    "    inlier_ratio_iqr = float(h2.loc[mask_ratio, \"inlier_ratio\"].quantile(0.75) - h2.loc[mask_ratio, \"inlier_ratio\"].quantile(0.25)) if mask_ratio.any() else np.nan\n",
    "\n",
    "    # conf stats (kalau ada)\n",
    "    conf_med = float(h2.loc[h2[\"valid_minpts\"] == 1, \"conf\"].median()) if \"conf\" in h2.columns and (h2[\"valid_minpts\"]==1).any() else np.nan\n",
    "    conf_iqr = float(h2.loc[h2[\"valid_minpts\"] == 1, \"conf\"].quantile(0.75) - h2.loc[h2[\"valid_minpts\"] == 1, \"conf\"].quantile(0.25)) if \"conf\" in h2.columns and (h2[\"valid_minpts\"]==1).any() else np.nan\n",
    "\n",
    "    # centroid jitter dari Head-3\n",
    "    dmu_med = np.nan\n",
    "    dmu_p95 = np.nan\n",
    "    if p3.exists():\n",
    "        h3 = load_head3_one_file(p3)\n",
    "        if not h3.empty:\n",
    "            # drop NaN diff di baris pertama\n",
    "            d = h3[\"dmu\"].dropna()\n",
    "            if len(d) > 0:\n",
    "                dmu_med = float(d.median())\n",
    "                dmu_p95 = float(d.quantile(0.95))\n",
    "\n",
    "    return {\n",
    "        \"trial_name\": trial_name,\n",
    "        \"subject\": subject,\n",
    "        \"trial\": trial,\n",
    "        \"status\": \"ok\",\n",
    "        \"frames_total\": frames_total,\n",
    "        \"frames_valid\": frames_valid,\n",
    "        \"valid_rate\": valid_rate,\n",
    "        \"mid_gaps\": mid_gaps,\n",
    "        \"mid_gap_ratio\": mid_gap_ratio,\n",
    "        \"frames_empty_after\": frames_empty_after,\n",
    "        \"inlier_ratio_med\": inlier_ratio_med,\n",
    "        \"inlier_ratio_iqr\": inlier_ratio_iqr,\n",
    "        \"conf_med\": conf_med,\n",
    "        \"conf_iqr\": conf_iqr,\n",
    "        \"dmu_med\": dmu_med,\n",
    "        \"dmu_p95\": dmu_p95,\n",
    "        \"head2_path\": str(p2),\n",
    "        \"head3_path\": str(p3) if p3.exists() else \"\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91426557",
   "metadata": {},
   "source": [
    "CELL 6 — Jalankan evaluasi untuk SEMUA file (langsung full batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_all() -> pd.DataFrame:\n",
    "    rows = []\n",
    "    total = len(TRIAL_ROOTS) * len(SUBJECTS) * len(TRIALS)\n",
    "    k = 0\n",
    "\n",
    "    for trial_name, root in TRIAL_ROOTS.items():\n",
    "        for s in SUBJECTS:\n",
    "            for t in TRIALS:\n",
    "                k += 1\n",
    "                if k % 50 == 0:\n",
    "                    print(f\"Progress {k}/{total} ...\")\n",
    "                rows.append(evaluate_one_file(trial_name, root, s, t))\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "eval_df = run_evaluation_all()\n",
    "print(\"Done. Rows:\", len(eval_df))\n",
    "eval_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f846d",
   "metadata": {},
   "source": [
    "CELL 7 — Buat tabel ringkasan per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e94b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_trial(eval_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ok = eval_df[eval_df[\"status\"] == \"ok\"].copy()\n",
    "\n",
    "    # agregasi global per trial\n",
    "    g = ok.groupby(\"trial_name\", as_index=False).agg(\n",
    "        files=(\"trial\", \"count\"),\n",
    "        valid_rate_mean=(\"valid_rate\", \"mean\"),\n",
    "        mid_gap_ratio_mean=(\"mid_gap_ratio\", \"mean\"),\n",
    "        empty_after_mean=(\"frames_empty_after\", \"mean\"),\n",
    "        inlier_ratio_med_mean=(\"inlier_ratio_med\", \"mean\"),\n",
    "        inlier_ratio_iqr_mean=(\"inlier_ratio_iqr\", \"mean\"),\n",
    "        dmu_med_mean=(\"dmu_med\", \"mean\"),\n",
    "        dmu_p95_mean=(\"dmu_p95\", \"mean\"),\n",
    "        conf_med_mean=(\"conf_med\", \"mean\"),\n",
    "        conf_iqr_mean=(\"conf_iqr\", \"mean\"),\n",
    "    )\n",
    "\n",
    "    # rapikan\n",
    "    for c in g.columns:\n",
    "        if c.endswith(\"_mean\"):\n",
    "            g[c] = g[c].astype(float)\n",
    "\n",
    "    return g.sort_values(\"trial_name\").reset_index(drop=True)\n",
    "\n",
    "trial_summary = summarize_by_trial(eval_df)\n",
    "trial_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b807dd6c",
   "metadata": {},
   "source": [
    "CELL 8 — Tabel per subjek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fe8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_subject(eval_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ok = eval_df[eval_df[\"status\"] == \"ok\"].copy()\n",
    "    g = ok.groupby([\"trial_name\", \"subject\"], as_index=False).agg(\n",
    "        files=(\"trial\", \"count\"),\n",
    "        valid_rate_mean=(\"valid_rate\", \"mean\"),\n",
    "        mid_gap_ratio_mean=(\"mid_gap_ratio\", \"mean\"),\n",
    "        empty_after_mean=(\"frames_empty_after\", \"mean\"),\n",
    "        inlier_ratio_med_mean=(\"inlier_ratio_med\", \"mean\"),\n",
    "        dmu_med_mean=(\"dmu_med\", \"mean\"),\n",
    "        dmu_p95_mean=(\"dmu_p95\", \"mean\"),\n",
    "    )\n",
    "    return g.sort_values([\"trial_name\", \"subject\"]).reset_index(drop=True)\n",
    "\n",
    "subject_summary = summarize_by_subject(eval_df)\n",
    "subject_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e67006",
   "metadata": {},
   "source": [
    "CELL 9 — Keputusan sederhana otomatis (ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f42ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_trials(trial_summary: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = trial_summary.copy()\n",
    "\n",
    "    # Normalisasi sederhana (min-max) agar bisa dijumlahkan\n",
    "    def minmax(s, invert=False):\n",
    "        s = s.astype(float)\n",
    "        lo, hi = np.nanmin(s), np.nanmax(s)\n",
    "        if hi - lo < 1e-12:\n",
    "            return np.zeros_like(s)\n",
    "        x = (s - lo) / (hi - lo)\n",
    "        return (1 - x) if invert else x\n",
    "\n",
    "    # mid_gap & dmu harus kecil => invert=True\n",
    "    score = (\n",
    "        0.45 * minmax(df[\"mid_gap_ratio_mean\"], invert=True) +\n",
    "        0.35 * minmax(df[\"dmu_p95_mean\"], invert=True) +\n",
    "        0.20 * minmax(df[\"valid_rate_mean\"], invert=False)\n",
    "    )\n",
    "    df[\"score\"] = score\n",
    "    return df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "ranking = rank_trials(trial_summary)\n",
    "ranking\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
